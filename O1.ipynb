{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd1cc80",
   "metadata": {},
   "source": [
    "# O1: Clasificacion del Fallecimiento\n",
    "\n",
    "El objetivo de esta seccion en el proyecto es **\"predecir si un paciente falleció a partir de las demas caracteristicas contenidas en el dataset\"**. Esta tarea es clave para poder identificar de manera rapida, con un modelo de clasificacion, a que pacientes se les requiere un seguimiento o intervencion con prioridad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec87bc4",
   "metadata": {},
   "source": [
    "### 1. Configuracion Inicial para el desarrollo del proyecto\n",
    "\n",
    "Para poder empezar a desarrollar el proyecto tenemos que configurar el entorno de trabajo instalando las bibliotecas necesarias requeridas:\n",
    "\n",
    "- Pandas: para lecutar y manopulacion del dataset\n",
    "\n",
    "- numpy: para operaciones numericas y manejo de arrays\n",
    "\n",
    "- scikit-learn: para poder crear y evaluar modelos mediante: clasificacion, regresion, validacion cruzada, ajuste de hiperparámetros.\n",
    "\n",
    "- matplotlib: para la visualizacion de los resultados y graficos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4573ad",
   "metadata": {},
   "source": [
    "Primero instalamos las librerias mencionadas si no las tenemos instaladas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef5a63",
   "metadata": {},
   "source": [
    "!pip install pandas numpy scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa28b99",
   "metadata": {},
   "source": [
    "Posteriormente las importamos en nuestro proyecto para poder: cargar datos, transformarlos, dividirlos en conjuntos de entrenamiento y prueba y para luego modelarlos de forma sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb2f9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95463e72",
   "metadata": {},
   "source": [
    "### 2. Carga y Exploracion del Dataset\n",
    "\n",
    "Cargamos el archivo del dataset que queremos trabajar (en formato csv) e imprimimos las primeras lineas del dataset y la informacion general del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66fadbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
      "0      2            12    1             1  9999-99-99       97          2   \n",
      "1      2            12    2             1  9999-99-99       97          2   \n",
      "2      2             4    2             1  9999-99-99       97          2   \n",
      "3      2             9    1             1  9999-99-99       97          2   \n",
      "4      1            12    2             1  9999-99-99       97          2   \n",
      "\n",
      "   AGE  PREGNANT  DIABETES  ...  ASTHMA  INMSUPR  HYPERTENSION  OTHER_DISEASE  \\\n",
      "0   41         2         2  ...       2        2             2              2   \n",
      "1   57         2         1  ...       2        2             2              2   \n",
      "2   38         2         2  ...       2        2             2              2   \n",
      "3   68         2         2  ...       2        2             2              2   \n",
      "4   63         2         2  ...       2        2             1              2   \n",
      "\n",
      "   CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  TEST_RESULT  ICU  \n",
      "0               2        2              2        2            7   97  \n",
      "1               2        1              2        1            5   97  \n",
      "2               2        1              2        1            3   97  \n",
      "3               1        2              2        2            7   97  \n",
      "4               2        2              2        2            7   97  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   USMER           100000 non-null  int64 \n",
      " 1   MEDICAL_UNIT    100000 non-null  int64 \n",
      " 2   SEX             100000 non-null  int64 \n",
      " 3   PATIENT_TYPE    100000 non-null  int64 \n",
      " 4   DATE_DIED       100000 non-null  object\n",
      " 5   INTUBED         100000 non-null  int64 \n",
      " 6   PNEUMONIA       100000 non-null  int64 \n",
      " 7   AGE             100000 non-null  int64 \n",
      " 8   PREGNANT        100000 non-null  int64 \n",
      " 9   DIABETES        100000 non-null  int64 \n",
      " 10  COPD            100000 non-null  int64 \n",
      " 11  ASTHMA          100000 non-null  int64 \n",
      " 12  INMSUPR         100000 non-null  int64 \n",
      " 13  HYPERTENSION    100000 non-null  int64 \n",
      " 14  OTHER_DISEASE   100000 non-null  int64 \n",
      " 15  CARDIOVASCULAR  100000 non-null  int64 \n",
      " 16  OBESITY         100000 non-null  int64 \n",
      " 17  RENAL_CHRONIC   100000 non-null  int64 \n",
      " 18  TOBACCO         100000 non-null  int64 \n",
      " 19  TEST_RESULT     100000 non-null  int64 \n",
      " 20  ICU             100000 non-null  int64 \n",
      "dtypes: int64(20), object(1)\n",
      "memory usage: 16.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV\n",
    "df = pd.read_csv(\"custom_covid19.csv\")\n",
    "\n",
    "# Mostrar las primeras filas para ver el contenido\n",
    "print(df.head())\n",
    "\n",
    "# Información general del DataFrame\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5d4dc",
   "metadata": {},
   "source": [
    "Podemos ver las principales lineas del dataset en las que cada columna tiene un rango de valor dependiendo de su tipo de variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436ad92a",
   "metadata": {},
   "source": [
    "## 3. Procesamiento y Limpieza de Datos\n",
    "\n",
    "### 3.1 Crear la Variable \"Fallecido\"\n",
    "\n",
    "La columna \"DATE_DIED\" tiene el valor por defecto de \"9999-99-99\" cuando el paciente no esta fallecido, por lo que vamos a transformarla en una nueva variable binaria de valor 1 - yes ; 2 - no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f4f1160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FALLECIDO'] = df['DATE_DIED'].apply(lambda x: 2 if x == '9999-99-99' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e132bf",
   "metadata": {},
   "source": [
    "Volvemos a imprimir las primeras filas del dataset para poder comprobar que se han asignado los valores de la columna \"fallecido\" correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "146f718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
      "0      2            12    1             1  9999-99-99       97          2   \n",
      "1      2            12    2             1  9999-99-99       97          2   \n",
      "2      2             4    2             1  9999-99-99       97          2   \n",
      "3      2             9    1             1  9999-99-99       97          2   \n",
      "4      1            12    2             1  9999-99-99       97          2   \n",
      "\n",
      "   AGE  PREGNANT  DIABETES  ...  INMSUPR  HYPERTENSION  OTHER_DISEASE  \\\n",
      "0   41         2         2  ...        2             2              2   \n",
      "1   57         2         1  ...        2             2              2   \n",
      "2   38         2         2  ...        2             2              2   \n",
      "3   68         2         2  ...        2             2              2   \n",
      "4   63         2         2  ...        2             1              2   \n",
      "\n",
      "   CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  TEST_RESULT  ICU  \\\n",
      "0               2        2              2        2            7   97   \n",
      "1               2        1              2        1            5   97   \n",
      "2               2        1              2        1            3   97   \n",
      "3               1        2              2        2            7   97   \n",
      "4               2        2              2        2            7   97   \n",
      "\n",
      "   FALLECIDO  \n",
      "0          2  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 22 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   USMER           100000 non-null  int64 \n",
      " 1   MEDICAL_UNIT    100000 non-null  int64 \n",
      " 2   SEX             100000 non-null  int64 \n",
      " 3   PATIENT_TYPE    100000 non-null  int64 \n",
      " 4   DATE_DIED       100000 non-null  object\n",
      " 5   INTUBED         100000 non-null  int64 \n",
      " 6   PNEUMONIA       100000 non-null  int64 \n",
      " 7   AGE             100000 non-null  int64 \n",
      " 8   PREGNANT        100000 non-null  int64 \n",
      " 9   DIABETES        100000 non-null  int64 \n",
      " 10  COPD            100000 non-null  int64 \n",
      " 11  ASTHMA          100000 non-null  int64 \n",
      " 12  INMSUPR         100000 non-null  int64 \n",
      " 13  HYPERTENSION    100000 non-null  int64 \n",
      " 14  OTHER_DISEASE   100000 non-null  int64 \n",
      " 15  CARDIOVASCULAR  100000 non-null  int64 \n",
      " 16  OBESITY         100000 non-null  int64 \n",
      " 17  RENAL_CHRONIC   100000 non-null  int64 \n",
      " 18  TOBACCO         100000 non-null  int64 \n",
      " 19  TEST_RESULT     100000 non-null  int64 \n",
      " 20  ICU             100000 non-null  int64 \n",
      " 21  FALLECIDO       100000 non-null  int64 \n",
      "dtypes: int64(21), object(1)\n",
      "memory usage: 16.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para ver el contenido\n",
    "print(df.head())\n",
    "\n",
    "# Información general del DataFrame\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e572fd",
   "metadata": {},
   "source": [
    "### 3.2 Conversion de Variables Booleanas\n",
    "\n",
    "Existen variables en el dataset con valores de datos erroneos/perdidos por lo que tenemos que procesarlos de forma parecida a la nueva variable y establecer valores \"no determinados\".\n",
    "\n",
    "Por lo que vamos a establecer a los valores distintos a los correspondientes (1- yes , 2 - no) el valor no determinado \"np.nan\" a dichas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d0c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0af91afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USMER\n",
      "2    63139\n",
      "1    36861\n",
      "Name: count, dtype: int64\n",
      "INTUBED\n",
      "2.0    15310\n",
      "1.0     3199\n",
      "Name: count, dtype: int64\n",
      "PNEUMONIA\n",
      "2.0    85009\n",
      "1.0    13414\n",
      "Name: count, dtype: int64\n",
      "PREGNANT\n",
      "2.0    98841\n",
      "1.0      807\n",
      "Name: count, dtype: int64\n",
      "DIABETES\n",
      "2.0    87777\n",
      "1.0    11880\n",
      "Name: count, dtype: int64\n",
      "COPD\n",
      "2.0    98298\n",
      "1.0     1407\n",
      "Name: count, dtype: int64\n",
      "ASTHMA\n",
      "2.0    96706\n",
      "1.0     3007\n",
      "Name: count, dtype: int64\n",
      "INMSUPR\n",
      "2.0    98283\n",
      "1.0     1386\n",
      "Name: count, dtype: int64\n",
      "HYPERTENSION\n",
      "2.0    84182\n",
      "1.0    15517\n",
      "Name: count, dtype: int64\n",
      "OTHER_DISEASE\n",
      "2.0    96866\n",
      "1.0     2678\n",
      "Name: count, dtype: int64\n",
      "CARDIOVASCULAR\n",
      "2.0    97781\n",
      "1.0     1925\n",
      "Name: count, dtype: int64\n",
      "OBESITY\n",
      "2.0    84517\n",
      "1.0    15207\n",
      "Name: count, dtype: int64\n",
      "RENAL_CHRONIC\n",
      "2.0    97866\n",
      "1.0     1839\n",
      "Name: count, dtype: int64\n",
      "TOBACCO\n",
      "2.0    91710\n",
      "1.0     7964\n",
      "Name: count, dtype: int64\n",
      "ICU\n",
      "2.0    16840\n",
      "1.0     1658\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61747cd3",
   "metadata": {},
   "source": [
    "Mostramos los valores para ver si los cambios se han realizado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b15162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
      "0      2            12    1             1  9999-99-99      NaN        2.0   \n",
      "1      2            12    2             1  9999-99-99      NaN        2.0   \n",
      "2      2             4    2             1  9999-99-99      NaN        2.0   \n",
      "3      2             9    1             1  9999-99-99      NaN        2.0   \n",
      "4      1            12    2             1  9999-99-99      NaN        2.0   \n",
      "\n",
      "   AGE  PREGNANT  DIABETES  ...  INMSUPR  HYPERTENSION  OTHER_DISEASE  \\\n",
      "0   41       2.0       2.0  ...      2.0           2.0            2.0   \n",
      "1   57       2.0       1.0  ...      2.0           2.0            2.0   \n",
      "2   38       2.0       2.0  ...      2.0           2.0            2.0   \n",
      "3   68       2.0       2.0  ...      2.0           2.0            2.0   \n",
      "4   63       2.0       2.0  ...      2.0           1.0            2.0   \n",
      "\n",
      "   CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  TEST_RESULT  ICU  \\\n",
      "0             2.0      2.0            2.0      2.0            7  NaN   \n",
      "1             2.0      1.0            2.0      1.0            5  NaN   \n",
      "2             2.0      1.0            2.0      1.0            3  NaN   \n",
      "3             1.0      2.0            2.0      2.0            7  NaN   \n",
      "4             2.0      2.0            2.0      2.0            7  NaN   \n",
      "\n",
      "   FALLECIDO  \n",
      "0          2  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para ver el contenido\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ccc7cb",
   "metadata": {},
   "source": [
    "### 3.3 Deteccion de outliers\n",
    "\n",
    "Vamos a buscar outliers en las características continuas, en este caso, en AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0811109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(df['AGE'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9369da",
   "metadata": {},
   "source": [
    "Vemos una gran cantidad de outliers, aunque es realista que haya personas de 90-100 años. Pero, no es realista que haya personas de 110-120 años. Estas instancias las eliminaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ded851f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE\n",
       "30     2603\n",
       "32     2450\n",
       "31     2429\n",
       "28     2421\n",
       "34     2414\n",
       "       ... \n",
       "100       4\n",
       "103       4\n",
       "101       3\n",
       "102       3\n",
       "104       2\n",
       "Name: count, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['AGE'] < 110]\n",
    "\n",
    "df.value_counts('AGE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79c562",
   "metadata": {},
   "source": [
    "## 4. Modelado con la variable \"Fallecido\"\n",
    "\n",
    "Al haber generado el modelo de clasificacion del fallecido (O1), la variable objetivo es \"Fallecido\" con los valores binario (1- yes ; 2- no)\n",
    "\n",
    "### 4.1 Preparacion para la clasificaicion\n",
    "\n",
    "Extraemos 'X' e 'Y'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6e7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['DATE_DIED', 'FALLECIDO'])\n",
    "y = df['FALLECIDO']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12980c15",
   "metadata": {},
   "source": [
    "Vamos a ver como se divide y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71315fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALLECIDO\n",
       "2    92659\n",
       "1     7338\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('FALLECIDO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd531c18",
   "metadata": {},
   "source": [
    "Se observa un gran desequilibrio en el número de fallecidos respecto a los no fallecidos. Este desbalance puede afectar negativamente al rendimiento del modelo, ya que al entrenarse mayoritariamente con instancias de personas no fallecidas, podría sesgarse hacia la clase mayoritaria, resultando en una menor capacidad de predicción para la clase minoritaria (fallecidos). Por ello usaremos class_weight = balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b749d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, param_grid, model, scoring):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5,  scoring=scoring, n_jobs=-1)  \n",
    "    grid_search.fit(x,y)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a5c446",
   "metadata": {},
   "source": [
    "### 4.2 Division de los datos y creacion del modelo\n",
    "\n",
    "Para crear el modelo, dividimos los datos y entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "429f56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Crear un imputer. En este ejemplo usaremos 'most_frequent' ya que \n",
    "# es adecuado para variables categóricas o datos discretos.\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Ajustar el imputer en X_train y transformar tanto X_train como X_test\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7909f",
   "metadata": {},
   "source": [
    "Empezaremos optimizando 'accuracy' para ver como se comporta el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c038cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring optimizado:  accuracy\n",
      "Mejores hiperparámetros: {'C': 0.1, 'class_weight': None}\n",
      "Accuracy: 0.9469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.47      0.57      1506\n",
      "           2       0.96      0.99      0.97     18494\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.84      0.73      0.77     20000\n",
      "weighted avg       0.94      0.95      0.94     20000\n",
      "\n",
      "Scoring optimizado:  recall\n",
      "Mejores hiperparámetros: {'C': 0.1, 'class_weight': 'balanced'}\n",
      "Accuracy: 0.90065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.92      0.58      1506\n",
      "           2       0.99      0.90      0.94     18494\n",
      "\n",
      "    accuracy                           0.90     20000\n",
      "   macro avg       0.71      0.91      0.76     20000\n",
      "weighted avg       0.95      0.90      0.92     20000\n",
      "\n",
      "Scoring optimizado:  precision\n",
      "Mejores hiperparámetros: {'C': 0.1, 'class_weight': None}\n",
      "Accuracy: 0.9469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.47      0.57      1506\n",
      "           2       0.96      0.99      0.97     18494\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.84      0.73      0.77     20000\n",
      "weighted avg       0.94      0.95      0.94     20000\n",
      "\n",
      "Scoring optimizado:  f1\n",
      "Mejores hiperparámetros: {'C': 1, 'class_weight': None}\n",
      "Accuracy: 0.94725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.47      0.57      1506\n",
      "           2       0.96      0.99      0.97     18494\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.85      0.73      0.77     20000\n",
      "weighted avg       0.94      0.95      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un modelo de regresión logística y ajustar el hiperparámetro C\n",
    "#Además usamos class_weight = balanced \n",
    "scoring = ['accuracy', 'recall', 'precision', 'f1']\n",
    "models = []\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'class_weight': [None, 'balanced']}\n",
    "for sc in scoring:\n",
    "    model_lr = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "    grid_lr = train_model(X_train_imputed, y_train, param_grid, model_lr, sc)\n",
    "    model_lr = grid_lr.best_estimator_\n",
    "    models.append(model_lr)\n",
    "    # Predicciones y evaluación usando los datos imputados\n",
    "    print(\"Scoring optimizado: \", sc)\n",
    "    y_pred = model_lr.predict(X_test_imputed)\n",
    "    print(\"Mejores hiperparámetros:\", grid_lr.best_params_)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622084a2",
   "metadata": {},
   "source": [
    "## 5. Evaluacion e Interpretacion del modelo de clasificacion obtenido\n",
    "\n",
    "### 5.1 Revision de los resultados y eleccion de modelo\n",
    "\n",
    "Al optimizar accuracy, precision y f1-score podemos observar que los pacientes que fallecieron (tipo 1) tiene una precision del 73% y un recall del 47%, no obstante, para los no fallecidos (tipo 2) los valores son muy altos con una precision del 96% y un recall del 99%.\n",
    "\n",
    "Esto indica que el modelo es muy bueno para poder identificar los pacientes que no fallecieron pero le cuesta predecir correctamente la clase de los fallecidos.\n",
    "\n",
    "En cambio, al optimizar el recall, se logró detectar el 92% de los fallecimientos reales, aunque a costa de una menor precisión (43%) y un descenso en la precisión global a un 90%.\n",
    "\n",
    "En el contexto de este problema, es preferible detectar la mayoría de los fallecimientos, incluso si eso implica cometer más falsos positivos.\n",
    "Es más grave predecir que un paciente sobrevivirá y que finalmente fallezca (falso negativo), que predecir que morirá y que finalmente sobreviva (falso positivo).\n",
    "\n",
    "Por tanto, priorizar el recall permite reducir los falsos negativos, lo cual es crítico cuando se trata de identificar a personas en riesgo.\n",
    "\n",
    "Para poder ajustar este modelo, podemos modificar el umbral de decision o cambiar de modelo de clasificacion para intentar mejorar el recall y precision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f94010",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = models[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a6ece",
   "metadata": {},
   "source": [
    "A continuacion, vamos a cargar los archivos CSV de validacion dado para nuestro proyecto, los cuales mostraran un conjunto de pruebas a las que debemos someter nuestro modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa278a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
      "0      1            12    2             1  9999-99-99       97          2   \n",
      "1      2            12    2             1  9999-99-99       97          2   \n",
      "2      2            12    1             1  9999-99-99       97          2   \n",
      "3      1             4    2             1  9999-99-99       97          2   \n",
      "4      2             4    1             1  9999-99-99       97          2   \n",
      "\n",
      "   AGE  PREGNANT  DIABETES  ...  ASTHMA  INMSUPR  HYPERTENSION  OTHER_DISEASE  \\\n",
      "0   32         2         2  ...       2        2             2              2   \n",
      "1   37         2         2  ...       2        2             2              2   \n",
      "2   45         2         2  ...       2        2             2              2   \n",
      "3   49         2         2  ...       2        2             2              2   \n",
      "4   31         2         2  ...       2        2             2              2   \n",
      "\n",
      "   CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  TEST_RESULT  ICU  \n",
      "0               2        2              2        1            7   97  \n",
      "1               2        2              2        2            3   97  \n",
      "2               2        2              2        2            7   97  \n",
      "3               2        2              2        2            7   97  \n",
      "4               2        2              2        2            7   97  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   IS_DEAD\n",
      "0        2\n",
      "1        2\n",
      "2        2\n",
      "3        2\n",
      "4        2\n"
     ]
    }
   ],
   "source": [
    "# Importa pandas si aún no lo has hecho\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de prueba de características y las etiquetas verdaderas\n",
    "proj_test_data = pd.read_csv(\"proj-test-data.csv\")\n",
    "proj_test_class = pd.read_csv(\"proj-test-class.csv\")\n",
    "\n",
    "proj_test_class['IS_DEAD']=np.where(proj_test_class['IS_DEAD'] == 1, 1, 2)\n",
    "# Visualiza las primeras filas para revisar su estructura\n",
    "print(proj_test_data.head())\n",
    "print(proj_test_class.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad357d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c93d9b3",
   "metadata": {},
   "source": [
    "### 5.2 Preprocesamiento del conjunto de Prueba\n",
    "\n",
    "Para hacer que el modelo funcione, el conjunto de prueba debe de ser transformado al mismo formato al cual hemos transformado nuestro dataset base por el cual se basa nuestro modelo.\n",
    "\n",
    "Primero eliminamos la columna DATE_DIED:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79afc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj_test = proj_test_data.drop(columns=['DATE_DIED'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5766c5ac",
   "metadata": {},
   "source": [
    "Despues, limpiamos y aplicamos el imputer al igual que hemos hecho en el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ed8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "colums = [\n",
    "    'USMER', 'INTUBED', 'PNEUMONIA', 'PREGNANT', 'DIABETES', \n",
    "    'COPD', 'ASTHMA', 'INMSUPR', 'HYPERTENSION', 'OTHER_DISEASE', \n",
    "    'CARDIOVASCULAR', 'OBESITY', 'RENAL_CHRONIC', 'TOBACCO', 'ICU'\n",
    "]\n",
    "\n",
    "for col in colums:\n",
    "    X_proj_test[col] = X_proj_test[col].replace({97: np.nan, 98: np.nan, 99: np.nan})\n",
    "\n",
    "X_proj_test_imputed = imputer.transform(X_proj_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3cd8ec",
   "metadata": {},
   "source": [
    "### 5.3 Evaluacion del modelo de clasificacion\n",
    "\n",
    "Por ultimo, entrenamos el modelo para predecir el resultado en los datos de prueba, el cual posteriormente compara las predicciones con las del archivo \"proj-test-class.csv\". Además mostraremos los resultados y la matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b6aacec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba independiente: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         7\n",
      "           2       1.00      0.92      0.96        93\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.75      0.96      0.81       100\n",
      "weighted avg       0.96      0.93      0.94       100\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[ 7  0]\n",
      " [ 7 86]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_proj_pred = model_lr.predict(X_proj_test_imputed)\n",
    "\n",
    "print(\"Accuracy en el conjunto de prueba independiente:\", accuracy_score(proj_test_class, y_proj_pred))\n",
    "print(classification_report(proj_test_class, y_proj_pred))\n",
    "\n",
    "cm = confusion_matrix(proj_test_class, y_proj_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b809be",
   "metadata": {},
   "source": [
    "Accuracy global: 93%, lo que indica un buen desempeño general en la predicción.\n",
    "\n",
    "Fallecidos:\n",
    "El modelo detectó correctamente todos los pacientes fallecidos.\n",
    "Sin embargo, cuando predijo que alguien falleció, generó algunos falsos positivos, pero no omitió ningún caso crítico.\n",
    "\n",
    "No fallecidos:\n",
    "El modelo fue excelente al predecir pacientes que no fallecieron y cometió pocos errores al clasificar esta clase.\n",
    "\n",
    "\n",
    "En un contexto sanitario, estos resultados son excelentes, porque se logró detectar todos los casos críticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e8116",
   "metadata": {},
   "source": [
    "# O2 Predecir la edad del paciente a partir de las demas variables\n",
    "\n",
    "El objetivo O2 consite en predecir la edad de los pacientes utilizando las demas variables que estan en el dataset. Para hacer esto, tenemos que plantear un problema de regresion en el que emplearan tecnicas de preprocesamiento como pueden ser la manipulacion de valores faltantes y la eliminacion de las columnas irrelevantes. Ademas se evaluara distintos modelos. Todo esto nos permite identificar la relacion entre las caracteristicas del paciente con su edad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f83df",
   "metadata": {},
   "source": [
    "## 1. Preparacion del Dataset para la Regresion\n",
    "\n",
    "### 1.1 Seleccionar la Variable Objetivo y las caracteristicas\n",
    "\n",
    "Como queremos predecir la edad (AGE), la variable objetivo sera \"y_age\" y las caracteristicas seran el resto de columnas que creamos utiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96339a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE  PNEUMONIA  PREGNANT  DIABETES  \\\n",
      "0          2            12    1             1        2.0       2.0       2.0   \n",
      "1          2            12    2             1        2.0       2.0       1.0   \n",
      "2          2             4    2             1        2.0       2.0       2.0   \n",
      "3          2             9    1             1        2.0       2.0       2.0   \n",
      "4          1            12    2             1        2.0       2.0       2.0   \n",
      "...      ...           ...  ...           ...        ...       ...       ...   \n",
      "99995      1            12    1             1        2.0       2.0       2.0   \n",
      "99996      1            12    2             2        1.0       2.0       2.0   \n",
      "99997      2            12    2             2        1.0       2.0       2.0   \n",
      "99998      1            12    1             1        2.0       2.0       2.0   \n",
      "99999      2            12    1             1        2.0       2.0       2.0   \n",
      "\n",
      "       COPD  ASTHMA  INMSUPR  HYPERTENSION  OTHER_DISEASE  CARDIOVASCULAR  \\\n",
      "0       2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "1       2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "2       2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "3       2.0     2.0      2.0           2.0            2.0             1.0   \n",
      "4       2.0     2.0      2.0           1.0            2.0             2.0   \n",
      "...     ...     ...      ...           ...            ...             ...   \n",
      "99995   2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "99996   2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "99997   2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "99998   2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "99999   2.0     2.0      2.0           2.0            2.0             2.0   \n",
      "\n",
      "       OBESITY  RENAL_CHRONIC  TOBACCO  TEST_RESULT  ICU  FALLECIDO  \n",
      "0          2.0            2.0      2.0            7  NaN          2  \n",
      "1          1.0            2.0      1.0            5  NaN          2  \n",
      "2          1.0            2.0      1.0            3  NaN          2  \n",
      "3          2.0            2.0      2.0            7  NaN          2  \n",
      "4          2.0            2.0      2.0            7  NaN          2  \n",
      "...        ...            ...      ...          ...  ...        ...  \n",
      "99995      2.0            2.0      2.0            3  NaN          2  \n",
      "99996      2.0            2.0      2.0            3  2.0          1  \n",
      "99997      1.0            2.0      2.0            3  2.0          1  \n",
      "99998      1.0            2.0      2.0            3  NaN          2  \n",
      "99999      2.0            2.0      2.0            5  NaN          2  \n",
      "\n",
      "[99618 rows x 19 columns]\n",
      "0        0-44\n",
      "1         45+\n",
      "2        0-44\n",
      "3         45+\n",
      "4         45+\n",
      "         ... \n",
      "99995     45+\n",
      "99996     45+\n",
      "99997     45+\n",
      "99998     45+\n",
      "99999     45+\n",
      "Name: AGE_BIN, Length: 99618, dtype: category\n",
      "Categories (2, object): ['0-44' < '45+']\n"
     ]
    }
   ],
   "source": [
    "df = df[df['AGE'].between(0, 110)]\n",
    "\n",
    "# Apply age binning\n",
    "age_bins = [0, 45,  110] #This turns into 1 and 2\n",
    "age_labels = ['0-44', '45+']\n",
    "df['AGE_BIN'] = pd.cut(df['AGE'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Drop rows where AGE_BIN is NaN (can happen if AGE was NaN before filtering)\n",
    "df = df.dropna(subset=['AGE_BIN'])\n",
    "X_age = df.drop(columns=['AGE', 'DATE_DIED', 'AGE_BIN','INTUBED'])  # Drop the intubed one for now bc it has lots of NaNs\n",
    "y_age = df['AGE_BIN']\n",
    "print(X_age)\n",
    "print(y_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c7e7d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_age_encoded = label_encoder.fit_transform(y_age)\n",
    "y_age_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92339a2e",
   "metadata": {},
   "source": [
    "## 1.2 Division de los datos tanto en el Entrenamiento como en la Prueba\n",
    "\n",
    "Tenemos que dividir el dataset en \"Entrenamiento\" y en \"Prueba\" para poder evaluar la capacidad de generalizacion del modelo.\n",
    "\n",
    "Lo dividiremos en 80% entrenamiento y 20% prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59bc025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(X_age, y_age_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4919a95f",
   "metadata": {},
   "source": [
    "## 1.3 Comprobacion de valores faltantes\n",
    "\n",
    "Antes de entrenar el modelo, tenemos que comprobar los datos faltantes como paso en la seccion O1. Por lo que usaremos \"SimpleImputer\" para rellenar los valores que falten (NaN). En el caso de las variables numericas podemos usar la \"mediana\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57cc2099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  6.,  1., ...,  7.,  2.,  2.],\n",
       "       [ 1.,  8.,  1., ...,  3.,  2.,  2.],\n",
       "       [ 2., 12.,  2., ...,  7.,  2.,  2.],\n",
       "       ...,\n",
       "       [ 1.,  4.,  1., ...,  7.,  2.,  2.],\n",
       "       [ 2., 12.,  2., ...,  3.,  2.,  2.],\n",
       "       [ 2.,  4.,  1., ...,  3.,  2.,  2.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer_age = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "X_train_age_imputed = imputer_age.fit_transform(X_train_age)\n",
    "X_test_age_imputed = imputer_age.transform(X_test_age)\n",
    "X_train_age_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988a74f9",
   "metadata": {},
   "source": [
    "## 1.4 Seleccion y entrenamiento del modelo de regresion\n",
    "\n",
    "Podemos hacer dos tipos de regresion: Lineal Simple y RandomForestRegressor (No lineal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae261f",
   "metadata": {},
   "source": [
    "### Opcion 1: Random Forest Classifier\n",
    "\n",
    "En esta opcion, entrenamos un clasificador de Basque Random, la cual es eun modelo que se usa en relaciones no lineales entre las caracteristicas utiles y la edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c92fab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7417185304155792\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81     12266\n",
      "           1       0.74      0.51      0.60      7658\n",
      "\n",
      "    accuracy                           0.74     19924\n",
      "   macro avg       0.74      0.70      0.71     19924\n",
      "weighted avg       0.74      0.74      0.73     19924\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[10896  1370]\n",
      " [ 3776  3882]]\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     27\u001b[0m grid_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(rf, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mgrid_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_age_imputed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_age\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_rf\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     31\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m grid_rf\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_lr_age = RandomForestClassifier(random_state=42) \n",
    "model_lr_age.fit(X_train_age_imputed, y_train_age)\n",
    "\n",
    "y_pred_lr_age = model_lr_age.predict(X_test_age_imputed)\n",
    "y_pred_age_decoded = label_encoder.inverse_transform(y_pred_lr_age)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_age, y_pred_lr_age))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_age, y_pred_lr_age))\n",
    "cm = confusion_matrix(y_test_age, y_pred_lr_age)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)\n",
    "#0 es para jovenes, 1 es para personas mayores de 45. Pq experimenté otros valores y no daban buenos resultados.\n",
    "#La matriz de confusion simboliza si es joven, es viejo y si fue correctamente identificado (también falta entubamiento)\n",
    "\n",
    "#Otra forma de ser mas preciso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define un grid más amplio\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train_age_imputed, y_train_age)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_rf.best_params_)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_age_imputed)\n",
    "print(\"Accuracy optimizado:\", accuracy_score(y_test_age, y_pred))\n",
    "print(classification_report(y_test_age, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0d562",
   "metadata": {},
   "source": [
    "Como podemos ver, aunque da un resultado válido, podria ser mejor. Los falsos positivos son muy altos todavia, y también seria buena idea reducier los falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b34a4",
   "metadata": {},
   "source": [
    "### Completar(Alejandro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616e3af",
   "metadata": {},
   "source": [
    "## O3. Predecir idade dos pacientes mortos em base de se tiveram ou não Covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conseguir todas las lineas con pacientes muertos.\n",
    "mortos_df = df[df['DATE_DIED'] != '9999-99-99'].copy()\n",
    "mortos_df\n",
    "\n",
    "#resultado mejores key fold cross validation en el 1.4\n",
    "# Contraejemplo, relacionar la edad con el resto de variables (enfermedades) ya que por ejemplo casos como la UCI casi siempre son personas mayores y/o con otras enfermedades\n",
    "#red neuronal en el min y max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pacientes mortos com teste COVID positivo\n",
    "mortos_df['COVID_POSITIVE'] = mortos_df['TEST_RESULT'].apply(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "mortos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5839a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mortos_df[['AGE']]         \n",
    "y = mortos_df['COVID_POSITIVE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde316f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree \n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "mdl = DecisionTreeRegressor(max_depth=10, random_state=0) # No, DTs are not completely deterministic, hence the random_state\n",
    "mdl.fit(X_train, y_train)\n",
    "preds=mdl.predict(X_test)\n",
    "\n",
    "print(\"The RVE is: \", explained_variance_score(y_test, preds))\n",
    "#print(\"The RMSE is: \", root_mean_squared_error(y_test, preds, squared=False))\n",
    "      # 'squared' parameter is deprecated in 1.4 and will be removed in 1.6.\n",
    "      # Use root_mean_squared_error instead to calculate the root mean squared error. \n",
    "corr, pval=pearsonr(y_test, preds)\n",
    "print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "print(\"The Maximum Error is is: \", max_error(y_test, preds))\n",
    "print(\"The Mean Absolute Error is: \", mean_absolute_error(y_test, preds))\n",
    "\n",
    "\n",
    "#We can't confidently predict the age of the people who did and didn't have Covid using the people who died.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a90ac",
   "metadata": {},
   "source": [
    "## O3 Miguel\n",
    "\n",
    "Considerando solo a las personas que murieron, ¿Podemos predecir con confianza la edad de quienes si tuvieron covid y de quiernes no?\n",
    "\n",
    "Pruebas con 3 modelos:\n",
    "1. LinearRegresion\n",
    "2. KNeighborsRegressor\n",
    "3. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebdfbd",
   "metadata": {},
   "source": [
    "### 3.1 Filtrar solo pacientes fallecidos\n",
    "\n",
    "Creamos un nuevo DataFrame `df_deceased` que contiene únicamente las filas de `df` donde `FALLECIDO == 1` (es decir, los que murieron)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33145b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Bloque de preparación para O3 ───\n",
    "\n",
    "# 1) Importaciones necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 2) Recarga del CSV original\n",
    "df_o3 = pd.read_csv('custom_covid19.csv')\n",
    "\n",
    "# 3) Creamos la variable binaria 'FALLECIDO' (1=fallecido, 2=no)\n",
    "df_o3['FALLECIDO'] = df_o3['DATE_DIED'].apply(lambda x: 2 if x == '9999-99-99' else 1)\n",
    "\n",
    "# 4) Filtramos sólo los pacientes que sí fallecieron\n",
    "df_o3 = df_o3[df_o3['FALLECIDO'] == 1].copy()\n",
    "\n",
    "# 5) Eliminamos edades irreales\n",
    "df_o3 = df_o3[df_o3['AGE'].between(0, 110)]\n",
    "\n",
    "# 6) Generamos el indicador COVID_POSITIVE (1=tuvo COVID, 0=no)\n",
    "df_o3['COVID_POSITIVE'] = df_o3['TEST_RESULT'].apply(lambda x: 1 if x in [1,2,3] else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c574d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pacientes fallecidos: 7338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USMER</th>\n",
       "      <th>MEDICAL_UNIT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATIENT_TYPE</th>\n",
       "      <th>DATE_DIED</th>\n",
       "      <th>INTUBED</th>\n",
       "      <th>PNEUMONIA</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PREGNANT</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>...</th>\n",
       "      <th>INMSUPR</th>\n",
       "      <th>HYPERTENSION</th>\n",
       "      <th>OTHER_DISEASE</th>\n",
       "      <th>CARDIOVASCULAR</th>\n",
       "      <th>OBESITY</th>\n",
       "      <th>RENAL_CHRONIC</th>\n",
       "      <th>TOBACCO</th>\n",
       "      <th>TEST_RESULT</th>\n",
       "      <th>ICU</th>\n",
       "      <th>FALLECIDO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24/05/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25/06/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29/06/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20/07/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
       "26      1             4    2             2  24/05/2020      2.0        2.0   \n",
       "33      1             3    1             1  25/06/2020      NaN        1.0   \n",
       "38      2             4    2             2  14/07/2020      2.0        2.0   \n",
       "40      2            12    2             2  29/06/2020      2.0        1.0   \n",
       "50      1            12    2             2  20/07/2020      2.0        1.0   \n",
       "\n",
       "    AGE  PREGNANT  DIABETES  ...  INMSUPR  HYPERTENSION  OTHER_DISEASE  \\\n",
       "26   69       2.0       NaN  ...      NaN           1.0            NaN   \n",
       "33   60       2.0       1.0  ...      2.0           1.0            2.0   \n",
       "38   75       2.0       2.0  ...      2.0           1.0            2.0   \n",
       "40   65       2.0       2.0  ...      2.0           2.0            2.0   \n",
       "50   58       2.0       2.0  ...      2.0           2.0            2.0   \n",
       "\n",
       "    CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  TEST_RESULT  ICU  \\\n",
       "26             NaN      1.0            NaN      NaN            7  2.0   \n",
       "33             2.0      1.0            2.0      2.0            3  NaN   \n",
       "38             2.0      2.0            2.0      2.0            7  2.0   \n",
       "40             2.0      2.0            2.0      2.0            2  2.0   \n",
       "50             2.0      2.0            2.0      2.0            3  2.0   \n",
       "\n",
       "    FALLECIDO  \n",
       "26          1  \n",
       "33          1  \n",
       "38          1  \n",
       "40          1  \n",
       "50          1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Filtrado de pacientes fallecidos\n",
    "df_deceased = df[df['FALLECIDO'] == 1].copy()\n",
    "print(f\"Número de pacientes fallecidos: {len(df_deceased)}\")\n",
    "df_deceased.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6638d",
   "metadata": {},
   "source": [
    "### 3.2 Creamos la variable binaria COVID_POSITIVE en la que apartir de TEST_RESULT podemos definir:\n",
    "\n",
    "1 si el paciente tuvo COVID (TEST_RESULT en [1,2,3])\n",
    "\n",
    "0 en caso contrario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5c21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST_RESULT</th>\n",
       "      <th>COVID_POSITIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TEST_RESULT  COVID_POSITIVE\n",
       "343            1               1\n",
       "40             2               1\n",
       "33             3               1\n",
       "967            4               0\n",
       "218            5               0\n",
       "248            6               0\n",
       "26             7               0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 Generación de COVID_POSITIVE\n",
    "df_deceased['COVID_POSITIVE'] = df_deceased['TEST_RESULT'].apply(lambda x: 1 if x in [1,2,3] else 0)\n",
    "df_deceased[['TEST_RESULT','COVID_POSITIVE']].drop_duplicates().sort_values('TEST_RESULT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a6066",
   "metadata": {},
   "source": [
    "### 3.3 Preparar la matriz de features X_m y vector objetivo y_m\n",
    "\n",
    "X_m (caracteristicas): solo la columna COVID_POSITIVE\n",
    "\n",
    "Y_m (objetivo): la edad real AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_m: (7338, 1)\n",
      "Shape y_m: (7338,)\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Definición de X_m e y_m\n",
    "X_m = df_deceased[['COVID_POSITIVE']]   # matriz n×1 con el indicador de COVID\n",
    "y_m = df_deceased['AGE']                # vector de edades\n",
    "print(\"Shape X_m:\", X_m.shape)\n",
    "print(\"Shape y_m:\", y_m.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6592e7b",
   "metadata": {},
   "source": [
    "### 3.4 Division en entrenamiento y prueba\n",
    "\n",
    "Usamos un split 70-30% para evaluar la capacidad de generalizacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e546a196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: (5136, 1) Prueba: (2202, 1)\n"
     ]
    }
   ],
   "source": [
    "# 3.4 División train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_m, y_m,\n",
    "    test_size=0.30,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Entrenamiento:\", X_train_m.shape, \"Prueba:\", X_test_m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3c542",
   "metadata": {},
   "source": [
    "### 3.5 Entrenar y evaluar varios regresores\n",
    "\n",
    "1. Regresion Lineal\n",
    "\n",
    "2. K-Nearest Neighboors Regressor\n",
    "\n",
    "3. Random Forest Regressor\n",
    "\n",
    "Y comparamos MAE, MSE y R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LinearRegression ---\n",
      "MAE: 12.154\n",
      "MSE: 243.599\n",
      "R² : 0.000\n",
      "\n",
      "--- KNeighborsRegressor ---\n",
      "MAE: 12.663\n",
      "MSE: 276.453\n",
      "R² : -0.134\n",
      "\n",
      "--- RandomForestRegressor ---\n",
      "MAE: 12.154\n",
      "MSE: 243.608\n",
      "R² : 0.000\n"
     ]
    }
   ],
   "source": [
    "# 3.5 Entrenamiento y evaluación de modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "modelos = {\n",
    "    'LinearRegression'      : LinearRegression(),\n",
    "    'KNeighborsRegressor'   : KNeighborsRegressor(n_neighbors=5),\n",
    "    'RandomForestRegressor' : RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    # Ajuste\n",
    "    modelo.fit(X_train_m, y_train_m)\n",
    "    # Predicción\n",
    "    y_pred_m = modelo.predict(X_test_m)\n",
    "    # Métricas\n",
    "    mae = mean_absolute_error(y_test_m, y_pred_m)\n",
    "    mse = mean_squared_error(y_test_m, y_pred_m)\n",
    "    r2  = r2_score(y_test_m, y_pred_m)\n",
    "    print(f\"\\n--- {nombre} ---\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"MSE: {mse:.3f}\")\n",
    "    print(f\"R² : {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c23c61",
   "metadata": {},
   "source": [
    "MAE (Mean Absolute Error): error medio en años\n",
    "\n",
    "MSE (Mean Square Error): penaliza mas los errores grandes\n",
    "\n",
    "R2: proporcion de varianza explicada por el modelo ( 1 = perfecto, 0 = ninguna capacidad predictiva) valor entre 0-1\n",
    "\n",
    "Si el valor de R2 es menor de 0.3, podemos concluir que no podemos predecir la edad solo con si tuvieron COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['FALLECIDO'] = df['DATE_DIED'].apply(lambda x: 2 if x == '9999-99-99' else 1)\n",
    "    \n",
    "    df.drop(columns=['DATE_DIED'], inplace=True)\n",
    "\n",
    "    columns = df.columns.drop(['AGE'])\n",
    "\n",
    "    for col in columns:\n",
    "        df[col] = df[col].replace({97: np.nan, 98: np.nan, 99: np.nan})\n",
    "\n",
    "    df['TEST_RESULT'] = df['TEST_RESULT'].apply(lambda x: 1 if x in [1,2,3] else 0)\n",
    "    non_binary_columns = ['AGE', 'MEDICAL_UNIT']\n",
    "\n",
    "    df = df[df['AGE'].between(0, 110)]\n",
    "\n",
    "    binary_cols = df.columns.drop(non_binary_columns)\n",
    "\n",
    "    df[binary_cols] = df[binary_cols].replace({1:1, 2:0})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c2d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Version: COVID_only =====\n",
      "\n",
      "  -- LinearRegression --\n",
      "  MAE: 12.124\n",
      "  MSE: 240.782\n",
      "  R² : 0.001\n",
      "\n",
      "  -- KNeighborsRegressor --\n",
      "  MAE: 13.190\n",
      "  MSE: 278.672\n",
      "  R² : -0.157\n",
      "\n",
      "  -- RandomForestRegressor --\n",
      "  MAE: 12.125\n",
      "  MSE: 240.777\n",
      "  R² : 0.001\n",
      "\n",
      "===== Version: COVID_plus_gravedad =====\n",
      "\n",
      "  -- LinearRegression --\n",
      "  MAE: 12.123\n",
      "  MSE: 239.977\n",
      "  R² : 0.004\n",
      "\n",
      "  -- KNeighborsRegressor --\n",
      "  MAE: 12.211\n",
      "  MSE: 242.797\n",
      "  R² : -0.008\n",
      "\n",
      "  -- RandomForestRegressor --\n",
      "  MAE: 12.157\n",
      "  MSE: 241.505\n",
      "  R² : -0.002\n",
      "\n",
      "===== Version: All_features =====\n",
      "\n",
      "  -- LinearRegression --\n",
      "  MAE: 11.365\n",
      "  MSE: 215.223\n",
      "  R² : 0.107\n",
      "\n",
      "  -- KNeighborsRegressor --\n",
      "  MAE: 12.473\n",
      "  MSE: 252.750\n",
      "  R² : -0.049\n",
      "\n",
      "  -- RandomForestRegressor --\n",
      "  MAE: 12.370\n",
      "  MSE: 249.553\n",
      "  R² : -0.036\n"
     ]
    }
   ],
   "source": [
    "# ### O3.b: Contraejemplo – Predecir FALLECIDO con todas las variables disponibles\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection   import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline          import Pipeline\n",
    "from sklearn.compose           import ColumnTransformer\n",
    "from sklearn.impute            import SimpleImputer\n",
    "from sklearn.preprocessing     import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble          import RandomForestClassifier\n",
    "from sklearn.metrics           import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1) Carga y limpieza (usa tu función ya definida)\n",
    "df_full = pd.read_csv(\"custom_covid19.csv\")\n",
    "df_full = limpieza(df_full)        # aplica DATE_DIED→FALLECIDO, imputación de códigos 97/98/99, binarización, filtro de AGE\n",
    "\n",
    "# 2) Definir X e y para clasificación de FALLECIDO\n",
    "X_full = df_full.drop(columns=['FALLECIDO'])\n",
    "y_full = df_full['FALLECIDO']\n",
    "\n",
    "# 3) Identificar columnas categóricas y numéricas\n",
    "#    En este dataset prácticamente todas son discretas/categóricas binarias o de códigos\n",
    "cat_cols = X_full.columns.tolist()\n",
    "num_cols = []  # si tuvieras columnas realmente numéricas, las listarías aquí\n",
    "\n",
    "# 4) Preprocesador\n",
    "preprocessor_full = ColumnTransformer([\n",
    "    (\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\"), cat_cols),\n",
    "    (\"onehot\",      OneHotEncoder(handle_unknown=\"ignore\"),  cat_cols),\n",
    "], remainder=\"drop\", sparse_threshold=0)\n",
    "\n",
    "# 5) Pipeline con escalado (opcional para RF) y modelo\n",
    "pipe_full = Pipeline([\n",
    "    (\"pre\",   preprocessor_full),\n",
    "    (\"scale\", StandardScaler(with_mean=False)),  # with_mean=False para sparse / after one-hot\n",
    "    (\"clf\",   RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 6) GridSearchCV sobre algunos hiperparámetros clave\n",
    "param_grid_full = {\n",
    "    \"clf__n_estimators\":    [100, 300],\n",
    "    \"clf__max_depth\":       [None, 10, 20],\n",
    "    \"clf__min_samples_split\":[2, 5],\n",
    "    \"clf__class_weight\":    [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
    "    X_full, y_full, test_size=0.33, random_state=42, stratify=y_full)\n",
    "\n",
    "grid_full = GridSearchCV(\n",
    "    pipe_full,\n",
    "    param_grid_full,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_full.fit(X_train_f, y_train_f)\n",
    "\n",
    "# 7) Evaluación\n",
    "best_full = grid_full.best_estimator_\n",
    "y_pred_f = best_full.predict(X_test_f)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_full.best_params_)\n",
    "print(\"Accuracy (test):\", accuracy_score(y_test_f, y_pred_f))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_f, y_pred_f, target_names=[\"No Fallecido\",\"Fallecido\"]))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test_f, y_pred_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Version: COVID_only =====\n",
      "\n",
      "  -- LinearRegression --\n",
      "  MAE: 12.124\n",
      "  MSE: 240.782\n",
      "  R² : 0.001\n",
      "\n",
      "  -- KNeighborsRegressor --\n",
      "  MAE: 13.190\n",
      "  MSE: 278.672\n",
      "  R² : -0.157\n",
      "\n",
      "  -- RandomForestRegressor --\n",
      "  MAE: 12.125\n",
      "  MSE: 240.777\n",
      "  R² : 0.001\n",
      "\n",
      "===== Version: COVID_plus_gravedad =====\n",
      "\n",
      "  -- LinearRegression --\n",
      "  MAE: 12.106\n",
      "  MSE: 240.338\n",
      "  R² : 0.002\n",
      "\n",
      "  -- KNeighborsRegressor --\n",
      "  MAE: 12.398\n",
      "  MSE: 252.542\n",
      "  R² : -0.048\n",
      "\n",
      "  -- RandomForestRegressor --\n",
      "  MAE: 12.121\n",
      "  MSE: 239.705\n",
      "  R² : 0.005\n",
      "\n",
      "===== Version: All_features =====\n",
      "\n",
      "  -- LinearRegression --\n",
      "  MAE: 11.958\n",
      "  MSE: 235.897\n",
      "  R² : 0.021\n",
      "\n",
      "  -- KNeighborsRegressor --\n",
      "  MAE: 12.540\n",
      "  MSE: 252.603\n",
      "  R² : -0.048\n",
      "\n",
      "  -- RandomForestRegressor --\n",
      "  MAE: 12.329\n",
      "  MSE: 249.316\n",
      "  R² : -0.035\n"
     ]
    }
   ],
   "source": [
    "# ——————————————————————————————————————————\n",
    "# O3.b: Comparación de versiones para predecir AGE en fallecidos\n",
    "# ——————————————————————————————————————————\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection   import train_test_split\n",
    "from sklearn.impute            import SimpleImputer\n",
    "from sklearn.linear_model      import LinearRegression\n",
    "from sklearn.neighbors         import KNeighborsRegressor\n",
    "from sklearn.ensemble          import RandomForestRegressor\n",
    "from sklearn.metrics           import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 1) Filtrar sólo fallecidos y crear COVID_POSITIVE\n",
    "df_deceased = df_o3[df_o3['FALLECIDO'] == 1].copy()\n",
    "df_deceased['COVID_POSITIVE'] = df_deceased['TEST_RESULT'].apply(lambda x: 1 if x in [1,2,3] else 0)\n",
    "\n",
    "#Las dropeamos ya que no se usan en el modelo\n",
    "drop_cols = ['AGE','FALLECIDO','DATE_DIED','TEST_RESULT']\n",
    "\n",
    "# 2) Definir tres conjuntos de predictores\n",
    "features_sets = {\n",
    "    'COVID_only': ['COVID_POSITIVE'],\n",
    "    'COVID_plus_gravedad': ['COVID_POSITIVE', 'INTUBED', 'ICU'],\n",
    "    'All_features': [c for c in df_deceased.columns if c not in drop_cols]\n",
    "}\n",
    "\n",
    "# 3) Configurar modelos a probar\n",
    "modelos = {\n",
    "    'LinearRegression'      : LinearRegression(),\n",
    "    'KNeighborsRegressor'   : KNeighborsRegressor(n_neighbors=5),\n",
    "    'RandomForestRegressor' : RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# 4) Bucle de entrenamiento/evaluación\n",
    "for set_name, feats in features_sets.items():\n",
    "    print(f\"\\n===== Version: {set_name} =====\")\n",
    "    \n",
    "    # a) Definir X_m y y_m\n",
    "    X_m = df_deceased[feats]\n",
    "    y_m = df_deceased['AGE']\n",
    "    \n",
    "    # b) Train/Test split\n",
    "    X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "        X_m, y_m, test_size=0.33, random_state=42\n",
    "    )\n",
    "    \n",
    "    # c) Imputar NaNs si los hay\n",
    "    imp = SimpleImputer(strategy='most_frequent')\n",
    "    X_train_imp = imp.fit_transform(X_train_m)\n",
    "    X_test_imp  = imp.transform(X_test_m)\n",
    "    \n",
    "    # d) Probar cada modelo\n",
    "    for nombre, modelo in modelos.items():\n",
    "        modelo.fit(X_train_imp, y_train_m)               # ajuste\n",
    "        y_pred = modelo.predict(X_test_imp)              # predicción\n",
    "        \n",
    "        mae = mean_absolute_error(y_test_m, y_pred)\n",
    "        mse = mean_squared_error(y_test_m, y_pred)\n",
    "        r2  = r2_score(y_test_m, y_pred)\n",
    "        \n",
    "        print(f\"\\n  -- {nombre} --\")\n",
    "        print(f\"  MAE: {mae:.3f}\")\n",
    "        print(f\"  MSE: {mse:.3f}\")\n",
    "        print(f\"  R² : {r2:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
